{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread\n",
    "from glob import glob\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "# import cv2\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "if os.name == 'nt':\n",
    "    file_path = 'C:\\\\JL\\\\Master\\\\DSE_I2100_Applied Machine Learning and Data Mining\\\\Final_Project\\\\lgg-mri-segmentation\\\\'\n",
    "else:\n",
    "    file_path = os.path.join(os.path.expanduser(\"~\"), \"Downloads/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_img = glob(file_path + os.path.join('kaggle_3m','*','*_mask*'))\n",
    "train_img = [file.replace('_mask', '') for file in mask_img]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label(mask):\n",
    "    value = np.max(imread(mask))\n",
    "    return '1' if value > 0 else '0'\n",
    "df = pd.DataFrame({\"image\": train_img,\n",
    "                   \"mask\": mask_img,\n",
    "                  \"label\":[label(x) for x in mask_img]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3929"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>mask</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\JL\\Master\\DSE_I2100_Applied Machine Learnin...</td>\n",
       "      <td>C:\\JL\\Master\\DSE_I2100_Applied Machine Learnin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\JL\\Master\\DSE_I2100_Applied Machine Learnin...</td>\n",
       "      <td>C:\\JL\\Master\\DSE_I2100_Applied Machine Learnin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\JL\\Master\\DSE_I2100_Applied Machine Learnin...</td>\n",
       "      <td>C:\\JL\\Master\\DSE_I2100_Applied Machine Learnin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\JL\\Master\\DSE_I2100_Applied Machine Learnin...</td>\n",
       "      <td>C:\\JL\\Master\\DSE_I2100_Applied Machine Learnin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\JL\\Master\\DSE_I2100_Applied Machine Learnin...</td>\n",
       "      <td>C:\\JL\\Master\\DSE_I2100_Applied Machine Learnin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image  \\\n",
       "0  C:\\JL\\Master\\DSE_I2100_Applied Machine Learnin...   \n",
       "1  C:\\JL\\Master\\DSE_I2100_Applied Machine Learnin...   \n",
       "2  C:\\JL\\Master\\DSE_I2100_Applied Machine Learnin...   \n",
       "3  C:\\JL\\Master\\DSE_I2100_Applied Machine Learnin...   \n",
       "4  C:\\JL\\Master\\DSE_I2100_Applied Machine Learnin...   \n",
       "\n",
       "                                                mask label  \n",
       "0  C:\\JL\\Master\\DSE_I2100_Applied Machine Learnin...     0  \n",
       "1  C:\\JL\\Master\\DSE_I2100_Applied Machine Learnin...     1  \n",
       "2  C:\\JL\\Master\\DSE_I2100_Applied Machine Learnin...     1  \n",
       "3  C:\\JL\\Master\\DSE_I2100_Applied Machine Learnin...     1  \n",
       "4  C:\\JL\\Master\\DSE_I2100_Applied Machine Learnin...     1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAUlUlEQVR4nO3df7DldX3f8edLlh9GTVzCul12kSVmpcGkou4g/phGo/Jrmqw6SCH+2Bgzm1hodGpN0WQKmmJIq6ZqlRbHDWCIlKrUtdkJriTRMZXI4iA/ZdgoZHe7wgrKD400wLt/nM9tT5d77+es3HPPvXufj5nv3O95f77f73nfM3fO635/nO9JVSFJ0myeNOkGJEkLn2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0LqSLI2SSVZNsfbfWuSu5M8lOSnf4z1/yrJb8xlT9JMDAstaEnuTPLKxfacSV6c5C+SPJjk/iSfT3Lc0PjBwAeBk6rqqVV17zTbOCTJ+UnuSPKD1tfmJGufSG/Sj8OwkOZYkhcBXwA+BxwJHAN8A/jrJD/TFlsJHAbcMsumPg38CvCrwE8BzwWuB14xns6lmRkWWpSSPCnJuUn+Nsm9Sa5McngbmzpstDHJ3yX5bpLfHVr3yUkuTfK9JLcl+Z0ku9rYJ4FnAp9vh4d+Z+hpXz/d9qbx74HLqupDVfVgVd1XVb8HXAucn+TZwO1t2e8n+Ytpfr9XAq8CNlTVdVX1SFXdX1UfrapPTLP8s9qezL2tv8uTPH1o/N8k2d32dG5P8opWPyHJ9iQPtENiHxxa58Qk/zPJ95N8I8nLhsZ+Lcm32va+neT1s7weOhBUlZPTgp2AO4FXTlN/G4M33zXAocB/AT7VxtYCBXwceDKD/8gfBn6ujV8IfAlY3ta/Edg103P2trdPXz8BPAq8fJqxNwN79tnmshl+7wuBL3Vem78CfqPN/yyDcDkUWAF8GfiPbexYYCdw5NBzP6vNfxV4Y5t/KnBim18N3AucxuCfyle1xyuApwAPAMe2ZVcBz5n034rTeCf3LLRY/Rbwu1W1q6oeBs4HTt/nJPR7qurvq+obDA4DPbfVzwDeV1Xfq6pdwIdHfM6ZtjfscAZvrnumGdsDHDHic/30DNuYVlXtqKptVfVwVe1lcD7kF9vwowxC5LgkB1fVnVX1t23sH4CfTXJEVT1UVde2+huArVW1taoeq6ptwHYG4QHwGPDzSZ5cVXuqarbDaToAGBZarI4GrmqHSL4P3MbgTXHl0DLfGZr/IYP/nGFwHmHn0Njw/Gxm2t6w7zF4I101zdgq4LsjPte9M2xjWklWJrmiHWp6APgTWjBV1Q7g7QwC9Z623JFt1bcAzwa+meS6JP+s1Y8GXjf1+rbX+KXAqqr6AfDPGQT2niR/luQfj9qrFifDQovVTuDUqnr60HRYVe0eYd09DA4/TTlqn/Ef+1bM7Y30q8Drphk+A7hmxE19ETghyZrukgPvY9D3L1TVTzLYM8hQX39aVS9lEAIF/GGr31FVZwHPaLVPJ3kKg9f3k/u8vk+pqgvbeldX1asYBNo3GRyi0wHMsNBicHCSw4amZcB/Bi5IcjRAkhVJNoy4vSuBdyVZnmQ1cM4+43cDP/P41UZ2LrAxyW8neVp7nn8HvAh4zygbqKovAtsY7D29IMmytq3fSvLr06zyNOAh4P72O71zaiDJsUl+KcmhwI+Av2ew90OSNyRZUVWPAd9vqzzGYM/kl5OcnOSg9rq/LMmathezoYXKw+15H9vfF0mLi2GhxWArgze4qel84EPAFuALSR5kcLL7hSNu773ALuDbDP6D/zSDN70pfwD8Xjv88q/3t9mq+gpwMvBaBnsxdwHPA15aVXfsx6ZOZ/C7/1fgfuBmYH3reV/vAZ7flvsz4LNDY4cyOGH+XQaH0p4BvKuNnQLckuQhBq/pme28zE5gA/BuYC+DPY13MnjPeBLwr4D/BdzH4NzIW/fj99IilCq//EhLW5K3MniT/MXuwtIS5Z6Flpwkq5K8pH1W41jgHcBVk+5LWsjm9F430iJxCIPPZRzD4Dj9FcDHJtmQtNB5GEqS1OVhKElS1wF5GOqII46otWvXTroNSVpUrr/++u9W1Yrpxg7IsFi7di3bt2+fdBuStKgkuWumMQ9DSZK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSug7IT3DPhRe887JJt6AF6Pr/8KZJtyBNxNj2LJIcleQvk9ya5JYkb2v189uXyt/QptOG1nlXkh1Jbk9y8lD9lFbbkeTccfUsSZreOPcsHgHeUVVfT/I04Pok29rYH1XV+4cXTnIccCbwHOBI4ItJnt2GPwq8isFXYV6XZEtV3TrG3iVJQ8YWFlW1h8H3D1NVDya5DVg9yyobgCuq6mHg20l2ACe0sR1V9S2AJFe0ZQ0LSZon83KCO8laBl9Y/zetdE6SG5NsTrK81VYz+FL4Kbtabab6vs+xKcn2JNv37t0717+CJC1pYw+LJE8FPgO8vaoeAC4CngUcz2DP4wNz8TxVdXFVra+q9StWTHs7dknSj2msV0MlOZhBUFxeVZ8FqKq7h8Y/DvyP9nA3cNTQ6mtajVnqkqR5MM6roQJ8Aritqj44VF81tNhrgJvb/BbgzCSHJjkGWAd8DbgOWJfkmCSHMDgJvmVcfUuSHm+cexYvAd4I3JTkhlZ7N3BWkuOBAu4EfhOgqm5JciWDE9ePAGdX1aMASc4BrgYOAjZX1S1j7FuStI9xXg31FSDTDG2dZZ0LgAumqW+dbT1J0nh5uw9JUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSusYWFkmOSvKXSW5NckuSt7X64Um2Jbmj/Vze6kny4SQ7ktyY5PlD29rYlr8jycZx9SxJmt449yweAd5RVccBJwJnJzkOOBe4pqrWAde0xwCnAuvatAm4CAbhApwHvBA4AThvKmAkSfNjbGFRVXuq6utt/kHgNmA1sAG4tC12KfDqNr8BuKwGrgWenmQVcDKwraruq6rvAduAU8bVtyTp8eblnEWStcDzgL8BVlbVnjb0HWBlm18N7BxabVerzVTf9zk2JdmeZPvevXvn9heQpCVu7GGR5KnAZ4C3V9UDw2NVVUDNxfNU1cVVtb6q1q9YsWIuNilJasYaFkkOZhAUl1fVZ1v57nZ4ifbznlbfDRw1tPqaVpupLkmaJ+O8GirAJ4DbquqDQ0NbgKkrmjYCnxuqv6ldFXUicH87XHU1cFKS5e3E9kmtJkmaJ8vGuO2XAG8EbkpyQ6u9G7gQuDLJW4C7gDPa2FbgNGAH8EPgzQBVdV+S3weua8u9t6ruG2PfkqR9jC0squorQGYYfsU0yxdw9gzb2gxsnrvuJEn7w09wS5K6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkrrGFRZLNSe5JcvNQ7fwku5Pc0KbThsbelWRHktuTnDxUP6XVdiQ5d1z9SpJmNs49i0uAU6ap/1FVHd+mrQBJjgPOBJ7T1vlYkoOSHAR8FDgVOA44qy0rSZpHy8a14ar6cpK1Iy6+Abiiqh4Gvp1kB3BCG9tRVd8CSHJFW/bWue5XkjSzSZyzOCfJje0w1fJWWw3sHFpmV6vNVH+cJJuSbE+yfe/evePoW5KWrPkOi4uAZwHHA3uAD8zVhqvq4qpaX1XrV6xYMVeblSQxYlgkuWaUWk9V3V1Vj1bVY8DH+X+HmnYDRw0tuqbVZqpLkubRrGGR5LAkhwNHJFme5PA2rWWGw0Gd7a0aevgaYOpKqS3AmUkOTXIMsA74GnAdsC7JMUkOYXASfMv+Pq8k6YnpneD+TeDtwJHA9UBa/QHgP822YpJPAS9jEDS7gPOAlyU5HijgzrZ9quqWJFcyOHH9CHB2VT3atnMOcDVwELC5qm7Zn19QkvTEzRoWVfUh4ENJ/mVVfWR/NlxVZ01T/sQsy18AXDBNfSuwdX+eW5I0t0a6dLaqPpLkxcDa4XWq6rIx9SVJWkBGCoskn2RwFdMNwKOtXIBhIUlLwKgfylsPHFdVNc5mJEkL06ifs7gZ+EfjbESStHCNumdxBHBrkq8BD08Vq+pXxtKVJGlBGTUszh9nE5L2z9+99xcm3YIWoGf+25vGtu1Rr4b60tg6kCQteKNeDfUgg6ufAA4BDgZ+UFU/Oa7GJEkLx6h7Fk+bmk8SBrcJP3FcTUmSFpb9vutsDfx34OTespKkA8Ooh6FeO/TwSQw+d/GjsXQkSVpwRr0a6peH5h9hcBPADXPejSRpQRr1nMWbx92IJGnhGvXLj9YkuSrJPW36TJI1425OkrQwjHqC+48ZfOnQkW36fKtJkpaAUcNiRVX9cVU90qZLAL/oWpKWiFHD4t4kb0hyUJveANw7zsYkSQvHqGHx68AZwHeAPcDpwK+NqSdJ0gIz6qWz7wU2VtX3AJIcDryfQYhIkg5wo+5Z/JOpoACoqvuA542nJUnSQjNqWDwpyfKpB23PYtS9EknSIjfqG/4HgK8m+W/t8euAC8bTkiRpoRn1E9yXJdkO/FIrvbaqbh1fW5KkhWTkQ0ktHAwISVqC9vsW5ZKkpcewkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXWMLiySb21ew3jxUOzzJtiR3tJ/LWz1JPpxkR5Ibkzx/aJ2Nbfk7kmwcV7+SpJmNc8/iEuCUfWrnAtdU1TrgmvYY4FRgXZs2ARfB/71h4XnAC4ETgPOGb2goSZofYwuLqvoycN8+5Q3ApW3+UuDVQ/XLauBa4OlJVgEnA9uq6r52i/RtPD6AJEljNt/nLFZW1Z42/x1gZZtfDewcWm5Xq81Uf5wkm5JsT7J97969c9u1JC1xEzvBXVUF1Bxu7+KqWl9V61esWDFXm5UkMf9hcXc7vET7eU+r7waOGlpuTavNVJckzaP5DostwNQVTRuBzw3V39SuijoRuL8drroaOCnJ8nZi+6RWkyTNo7F9NWqSTwEvA45IsovBVU0XAlcmeQtwF3BGW3wrcBqwA/gh8GYYfNd3kt8HrmvLvbd9/7ckaR6NLSyq6qwZhl4xzbIFnD3DdjYDm+ewNUnSfvIT3JKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqWsiYZHkziQ3JbkhyfZWOzzJtiR3tJ/LWz1JPpxkR5Ibkzx/Ej1L0lI2yT2Ll1fV8VW1vj0+F7imqtYB17THAKcC69q0Cbho3juVpCVuIR2G2gBc2uYvBV49VL+sBq4Fnp5k1QT6k6Qla1JhUcAXklyfZFOrrayqPW3+O8DKNr8a2Dm07q5W+/8k2ZRke5Lte/fuHVffkrQkLZvQ8760qnYneQawLck3hwerqpLU/mywqi4GLgZYv379fq0rSZrdRPYsqmp3+3kPcBVwAnD31OGl9vOetvhu4Kih1de0miRpnsx7WCR5SpKnTc0DJwE3A1uAjW2xjcDn2vwW4E3tqqgTgfuHDldJkubBJA5DrQSuSjL1/H9aVX+e5DrgyiRvAe4CzmjLbwVOA3YAPwTePP8tS9LSNu9hUVXfAp47Tf1e4BXT1As4ex5akyTNYCFdOitJWqAMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1LVowiLJKUluT7IjybmT7keSlpJFERZJDgI+CpwKHAecleS4yXYlSUvHoggL4ARgR1V9q6r+N3AFsGHCPUnSkrFs0g2MaDWwc+jxLuCFwwsk2QRsag8fSnL7PPW2FBwBfHfSTSwEef/GSbegx/Pvc8p5eaJbOHqmgcUSFl1VdTFw8aT7OBAl2V5V6yfdhzQd/z7nx2I5DLUbOGro8ZpWkyTNg8USFtcB65Ick+QQ4Exgy4R7kqQlY1EchqqqR5KcA1wNHARsrqpbJtzWUuLhPS1k/n3Og1TVpHuQJC1wi+UwlCRpggwLSVKXYaFZeZsVLURJNie5J8nNk+5lqTAsNCNvs6IF7BLglEk3sZQYFpqNt1nRglRVXwbum3QfS4lhodlMd5uV1RPqRdIEGRaSpC7DQrPxNiuSAMNCs/M2K5IAw0KzqKpHgKnbrNwGXOltVrQQJPkU8FXg2CS7krxl0j0d6LzdhySpyz0LSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRbSHEjyUGd87f7eITXJJUlOf2KdSXPDsJAkdRkW0hxK8tQk1yT5epKbkgzfpXdZksuT3Jbk00l+oq3zgiRfSnJ9kquTrJpQ+9KMDAtpbv0IeE1VPR94OfCBJGljxwIfq6qfAx4A/kWSg4GPAKdX1QuAzcAFE+hbmtWySTcgHWACvC/JPwUeY3BL95VtbGdV/XWb/xPgt4E/B34e2NYy5SBgz7x2LI3AsJDm1uuBFcALquofktwJHNbG9r23TjEIl1uq6kXz16K0/zwMJc2tnwLuaUHxcuDoobFnJpkKhV8FvgLcDqyYqic5OMlz5rVjaQSGhTS3LgfWJ7kJeBPwzaGx24Gzk9wGLAcual9Xezrwh0m+AdwAvHh+W5b6vOusJKnLPQtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktT1fwDjE0Y852lWvAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data=df,x=df['label'])\n",
    "plt.title('Length Of Classes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save images to a list\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.io import imread\n",
    "IMAGE_LIST = [ imread(path) for path in df[\"image\"]  ]\n",
    "GRAY_IMAGE_LIST = [rgb2gray(rgb_img) for rgb_img in IMAGE_LIST]\n",
    "\n",
    "IMAGE_LIST = np.array(IMAGE_LIST)\n",
    "GRAY_IMAGE_LIST = np.array(GRAY_IMAGE_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3929, 256, 256, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMAGE_LIST.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect mage size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_WIDTH_LIST = []\n",
    "IMAGE_HEIGHT_LIST = []\n",
    "\n",
    "for path in df['image']:\n",
    "  IMAGE_WIDTH_LIST.append(imread(path).shape[0])\n",
    "  IMAGE_HEIGHT_LIST.append(imread(path).shape[1])\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(8, 6))\n",
    "width_hist = axes[0].hist(IMAGE_WIDTH_LIST)\n",
    "height_hist = axes[1].hist(IMAGE_HEIGHT_LIST)\n",
    "axes[0].set_title(\"Histogram of image width\")\n",
    "axes[1].set_title(\"Histogram of image height\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View first 5 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_and_mask(img_path, mask_path):\n",
    "    rgb_img = imread(img_path)\n",
    "    gray_img = rgb2gray(rgb_img)\n",
    "    mask_img = imread(mask_path)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(10, 8))\n",
    "    ax = axes.ravel()\n",
    "    ax[0].imshow(rgb_img)\n",
    "    ax[0].set_title(\"Original\")\n",
    "    ax[1].imshow(gray_img, cmap=plt.cm.gray)\n",
    "    ax[1].set_title(\"Grayscale\")\n",
    "    ax[2].imshow(mask_img)\n",
    "    ax[2].set_title(\"Mask\")\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(5):\n",
    "    test_img = df.iloc[idx, 0]\n",
    "    test_img_mask = df.iloc[idx, 1]\n",
    "    show_image_and_mask(test_img, test_img_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram of pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 8))\n",
    "rgb_pixel_hist = axes[0].hist(IMAGE_LIST.reshape(-1))\n",
    "gray_pixel_hist = axes[1].hist(GRAY_IMAGE_LIST.reshape(-1))\n",
    "axes[0].set_title(\"Histogram of pixels in RGB images\")\n",
    "axes[1].set_title(\"Histogram of pixels in gray images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = IMAGE_LIST\n",
    "label = np.array(df[\"label\"].values).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3929, 256, 256, 3)\n",
      "(3929,)\n"
     ]
    }
   ],
   "source": [
    "print(dataset.shape)\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#from keras.utils import to_categorical\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset, label, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.utils import normalize\n",
    "# X_train = normalize(X_train, axis=1)\n",
    "# X_test = normalize(X_test, axis=1)\n",
    "X_train = X_train / 255.\n",
    "X_test = X_test / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (256, 256, 3)   #change to (SIZE, SIZE, 3)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape=INPUT_SHAPE))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), kernel_initializer = 'he_uniform'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), kernel_initializer = 'he_uniform'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 254, 254, 32)      896       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 254, 254, 32)      0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 127, 127, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 125, 125, 32)      9248      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 125, 125, 32)      0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 62, 62, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 60, 60, 64)        18496     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 60, 60, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 30, 30, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 57600)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                3686464   \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 64)                0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,715,169\n",
      "Trainable params: 3,715,169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',             #also try adam\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "99/99 [==============================] - 7s 68ms/step - loss: 0.2883 - accuracy: 0.8533 - val_loss: 0.2775 - val_accuracy: 0.8677\n",
      "Epoch 2/20\n",
      "99/99 [==============================] - 7s 67ms/step - loss: 0.2649 - accuracy: 0.8753 - val_loss: 0.2795 - val_accuracy: 0.8766\n",
      "Epoch 3/20\n",
      "99/99 [==============================] - 7s 66ms/step - loss: 0.2298 - accuracy: 0.8915 - val_loss: 0.2661 - val_accuracy: 0.8715\n",
      "Epoch 4/20\n",
      "99/99 [==============================] - 7s 67ms/step - loss: 0.2211 - accuracy: 0.9055 - val_loss: 0.2328 - val_accuracy: 0.8893\n",
      "Epoch 5/20\n",
      "99/99 [==============================] - 7s 67ms/step - loss: 0.2207 - accuracy: 0.9001 - val_loss: 0.2229 - val_accuracy: 0.9008\n",
      "Epoch 6/20\n",
      "99/99 [==============================] - 7s 67ms/step - loss: 0.1822 - accuracy: 0.9173 - val_loss: 0.2277 - val_accuracy: 0.8957\n",
      "Epoch 7/20\n",
      "99/99 [==============================] - 7s 67ms/step - loss: 0.1685 - accuracy: 0.9281 - val_loss: 0.2259 - val_accuracy: 0.9059\n",
      "Epoch 8/20\n",
      "99/99 [==============================] - 7s 67ms/step - loss: 0.1701 - accuracy: 0.9262 - val_loss: 0.2125 - val_accuracy: 0.9059\n",
      "Epoch 9/20\n",
      "99/99 [==============================] - 7s 67ms/step - loss: 0.1476 - accuracy: 0.9386 - val_loss: 0.2541 - val_accuracy: 0.9173\n",
      "Epoch 10/20\n",
      "99/99 [==============================] - 7s 67ms/step - loss: 0.1494 - accuracy: 0.9373 - val_loss: 0.2408 - val_accuracy: 0.9084\n",
      "Epoch 11/20\n",
      "99/99 [==============================] - 7s 67ms/step - loss: 0.1323 - accuracy: 0.9434 - val_loss: 0.2430 - val_accuracy: 0.9135\n",
      "Epoch 12/20\n",
      "99/99 [==============================] - 7s 67ms/step - loss: 0.1104 - accuracy: 0.9555 - val_loss: 0.3200 - val_accuracy: 0.8931\n",
      "Epoch 13/20\n",
      "99/99 [==============================] - 7s 67ms/step - loss: 0.1084 - accuracy: 0.9599 - val_loss: 0.2900 - val_accuracy: 0.9046\n",
      "Epoch 14/20\n",
      "99/99 [==============================] - 7s 67ms/step - loss: 0.1008 - accuracy: 0.9586 - val_loss: 0.2687 - val_accuracy: 0.9097\n",
      "Epoch 15/20\n",
      "99/99 [==============================] - 7s 67ms/step - loss: 0.1161 - accuracy: 0.9609 - val_loss: 0.2537 - val_accuracy: 0.9109\n",
      "Epoch 16/20\n",
      "99/99 [==============================] - 7s 67ms/step - loss: 0.1089 - accuracy: 0.9570 - val_loss: 0.2398 - val_accuracy: 0.9135\n",
      "Epoch 17/20\n",
      "99/99 [==============================] - 7s 67ms/step - loss: 0.0821 - accuracy: 0.9714 - val_loss: 0.2811 - val_accuracy: 0.9160\n",
      "Epoch 18/20\n",
      "99/99 [==============================] - 7s 67ms/step - loss: 0.0851 - accuracy: 0.9704 - val_loss: 0.2861 - val_accuracy: 0.9109\n",
      "Epoch 19/20\n",
      "99/99 [==============================] - 7s 67ms/step - loss: 0.0671 - accuracy: 0.9752 - val_loss: 0.3052 - val_accuracy: 0.9135\n",
      "Epoch 20/20\n",
      "99/99 [==============================] - 7s 67ms/step - loss: 0.0766 - accuracy: 0.9701 - val_loss: 0.3018 - val_accuracy: 0.9097\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\"\n",
    "# sess = tf.Session(config=tf.ConfigProto(device_count={'GPU': 0}))\n",
    "\n",
    "# with tf.device('/CPU:0'):\n",
    "#     history = model.fit(X_train, \n",
    "#                             y_train, \n",
    "#                             batch_size = 32, \n",
    "#                             verbose = 1, \n",
    "#                             epochs = 20,      \n",
    "#                             validation_data=(X_test,y_test),\n",
    "#                             shuffle = True\n",
    "#                         )\n",
    "history = model.fit(X_train, \n",
    "                            y_train, \n",
    "                            batch_size = 32, \n",
    "                            verbose = 1, \n",
    "                            epochs = 20,      \n",
    "                            validation_data=(X_test,y_test),\n",
    "                            shuffle = True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 8s 313ms/step - loss: 0.3018 - accuracy: 0.9097\n",
      "Accuracy =  90.96692204475403 %\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    _, acc = model.evaluate(X_test, y_test)\n",
    "print(\"Accuracy = \", (acc * 100.0), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mythreshold=0.5\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "y_pred = (model.predict(X_test)>= mythreshold).astype(int)\n",
    "cm=confusion_matrix(y_test, y_pred)  \n",
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "y_preds = model.predict(X_test).ravel()\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_preds)\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'y--')\n",
    "plt.plot(fpr, tpr, marker='.')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc\n",
    "auc_value = auc(fpr, tpr)\n",
    "print(\"Area under curve, AUC = \", auc_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "len(tf.config.experimental.list_physical_devices(\"GPU\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.experimental.get_memory_info('GPU:0')['current'] / 10**9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "c = tf.matmul(a, b)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e3f8286b7aee863f6cbe79a9a5c8ff66e6a875b07d32e8812c10b72f75b5386d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
