{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread\n",
    "from glob import glob\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "# import cv2\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "if os.name == 'nt':\n",
    "    file_path = 'C:\\\\JL\\\\Master\\\\DSE_I2100_Applied Machine Learning and Data Mining\\\\Final_Project\\\\lgg-mri-segmentation\\\\'\n",
    "else:\n",
    "    file_path = os.path.join(os.path.expanduser(\"~\"), \"Downloads/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_img = glob(file_path + os.path.join('kaggle_3m','*','*_mask*'))\n",
    "train_img = [file.replace('_mask', '') for file in mask_img]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label(mask):\n",
    "    value = np.max(imread(mask))\n",
    "    return '1' if value > 0 else '0'\n",
    "df = pd.DataFrame({\"image\": train_img,\n",
    "                   \"mask\": mask_img,\n",
    "                  \"label\":[label(x) for x in mask_img]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5302"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>mask</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\JL\\Master\\DSE_I2100_Applied Machine Learnin...</td>\n",
       "      <td>C:\\JL\\Master\\DSE_I2100_Applied Machine Learnin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\JL\\Master\\DSE_I2100_Applied Machine Learnin...</td>\n",
       "      <td>C:\\JL\\Master\\DSE_I2100_Applied Machine Learnin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\JL\\Master\\DSE_I2100_Applied Machine Learnin...</td>\n",
       "      <td>C:\\JL\\Master\\DSE_I2100_Applied Machine Learnin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\JL\\Master\\DSE_I2100_Applied Machine Learnin...</td>\n",
       "      <td>C:\\JL\\Master\\DSE_I2100_Applied Machine Learnin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\JL\\Master\\DSE_I2100_Applied Machine Learnin...</td>\n",
       "      <td>C:\\JL\\Master\\DSE_I2100_Applied Machine Learnin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image  \\\n",
       "0  C:\\JL\\Master\\DSE_I2100_Applied Machine Learnin...   \n",
       "1  C:\\JL\\Master\\DSE_I2100_Applied Machine Learnin...   \n",
       "2  C:\\JL\\Master\\DSE_I2100_Applied Machine Learnin...   \n",
       "3  C:\\JL\\Master\\DSE_I2100_Applied Machine Learnin...   \n",
       "4  C:\\JL\\Master\\DSE_I2100_Applied Machine Learnin...   \n",
       "\n",
       "                                                mask label  \n",
       "0  C:\\JL\\Master\\DSE_I2100_Applied Machine Learnin...     1  \n",
       "1  C:\\JL\\Master\\DSE_I2100_Applied Machine Learnin...     1  \n",
       "2  C:\\JL\\Master\\DSE_I2100_Applied Machine Learnin...     1  \n",
       "3  C:\\JL\\Master\\DSE_I2100_Applied Machine Learnin...     1  \n",
       "4  C:\\JL\\Master\\DSE_I2100_Applied Machine Learnin...     1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data=df,x=df['label'])\n",
    "plt.title('Length Of Classes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save images to a list\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.io import imread\n",
    "IMAGE_LIST = [ imread(path) for path in df[\"image\"]  ]\n",
    "GRAY_IMAGE_LIST = [rgb2gray(rgb_img) for rgb_img in IMAGE_LIST]\n",
    "\n",
    "IMAGE_LIST = np.array(IMAGE_LIST)\n",
    "GRAY_IMAGE_LIST = np.array(GRAY_IMAGE_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3929, 256, 256, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMAGE_LIST.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect mage size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_WIDTH_LIST = []\n",
    "IMAGE_HEIGHT_LIST = []\n",
    "\n",
    "for path in df['image']:\n",
    "  IMAGE_WIDTH_LIST.append(imread(path).shape[0])\n",
    "  IMAGE_HEIGHT_LIST.append(imread(path).shape[1])\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(8, 6))\n",
    "width_hist = axes[0].hist(IMAGE_WIDTH_LIST)\n",
    "height_hist = axes[1].hist(IMAGE_HEIGHT_LIST)\n",
    "axes[0].set_title(\"Histogram of image width\")\n",
    "axes[1].set_title(\"Histogram of image height\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View first 5 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_and_mask(img_path, mask_path):\n",
    "    rgb_img = imread(img_path)\n",
    "    gray_img = rgb2gray(rgb_img)\n",
    "    mask_img = imread(mask_path)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(10, 8))\n",
    "    ax = axes.ravel()\n",
    "    ax[0].imshow(rgb_img)\n",
    "    ax[0].set_title(\"Original\")\n",
    "    ax[1].imshow(gray_img, cmap=plt.cm.gray)\n",
    "    ax[1].set_title(\"Grayscale\")\n",
    "    ax[2].imshow(mask_img)\n",
    "    ax[2].set_title(\"Mask\")\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(5):\n",
    "    test_img = df.iloc[idx, 0]\n",
    "    test_img_mask = df.iloc[idx, 1]\n",
    "    show_image_and_mask(test_img, test_img_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram of pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 8))\n",
    "rgb_pixel_hist = axes[0].hist(IMAGE_LIST.reshape(-1))\n",
    "gray_pixel_hist = axes[1].hist(GRAY_IMAGE_LIST.reshape(-1))\n",
    "axes[0].set_title(\"Histogram of pixels in RGB images\")\n",
    "axes[1].set_title(\"Histogram of pixels in gray images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = IMAGE_LIST\n",
    "label = np.array(df[\"label\"].values).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3929, 256, 256, 3)\n",
      "(3929,)\n"
     ]
    }
   ],
   "source": [
    "print(dataset.shape)\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#from keras.utils import to_categorical\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset, label, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.utils import normalize\n",
    "# X_train = normalize(X_train, axis=1)\n",
    "# X_test = normalize(X_test, axis=1)\n",
    "X_train = X_train / 255.\n",
    "X_test = X_test / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (256, 256, 3)   #change to (SIZE, SIZE, 3)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape=INPUT_SHAPE))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), kernel_initializer = 'he_uniform'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), kernel_initializer = 'he_uniform'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 254, 254, 32)      896       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 254, 254, 32)      0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 127, 127, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 125, 125, 32)      9248      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 125, 125, 32)      0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 62, 62, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 60, 60, 64)        18496     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 60, 60, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 30, 30, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 57600)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                3686464   \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 64)                0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,715,169\n",
      "Trainable params: 3,715,169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',             #also try adam\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "99/99 [==============================] - 7s 68ms/step - loss: 0.2883 - accuracy: 0.8533 - val_loss: 0.2775 - val_accuracy: 0.8677\n",
      "Epoch 2/20\n",
      "99/99 [==============================] - 7s 67ms/step - loss: 0.2649 - accuracy: 0.8753 - val_loss: 0.2795 - val_accuracy: 0.8766\n",
      "Epoch 3/20\n",
      "99/99 [==============================] - 7s 66ms/step - loss: 0.2298 - accuracy: 0.8915 - val_loss: 0.2661 - val_accuracy: 0.8715\n",
      "Epoch 4/20\n",
      "99/99 [==============================] - 7s 67ms/step - loss: 0.2211 - accuracy: 0.9055 - val_loss: 0.2328 - val_accuracy: 0.8893\n",
      "Epoch 5/20\n",
      "99/99 [==============================] - 7s 67ms/step - loss: 0.2207 - accuracy: 0.9001 - val_loss: 0.2229 - val_accuracy: 0.9008\n",
      "Epoch 6/20\n",
      "99/99 [==============================] - 7s 67ms/step - loss: 0.1822 - accuracy: 0.9173 - val_loss: 0.2277 - val_accuracy: 0.8957\n",
      "Epoch 7/20\n",
      "99/99 [==============================] - 7s 67ms/step - loss: 0.1685 - accuracy: 0.9281 - val_loss: 0.2259 - val_accuracy: 0.9059\n",
      "Epoch 8/20\n",
      "99/99 [==============================] - 7s 67ms/step - loss: 0.1701 - accuracy: 0.9262 - val_loss: 0.2125 - val_accuracy: 0.9059\n",
      "Epoch 9/20\n",
      "99/99 [==============================] - 7s 67ms/step - loss: 0.1476 - accuracy: 0.9386 - val_loss: 0.2541 - val_accuracy: 0.9173\n",
      "Epoch 10/20\n",
      "99/99 [==============================] - 7s 67ms/step - loss: 0.1494 - accuracy: 0.9373 - val_loss: 0.2408 - val_accuracy: 0.9084\n",
      "Epoch 11/20\n",
      "99/99 [==============================] - 7s 67ms/step - loss: 0.1323 - accuracy: 0.9434 - val_loss: 0.2430 - val_accuracy: 0.9135\n",
      "Epoch 12/20\n",
      "99/99 [==============================] - 7s 67ms/step - loss: 0.1104 - accuracy: 0.9555 - val_loss: 0.3200 - val_accuracy: 0.8931\n",
      "Epoch 13/20\n",
      "99/99 [==============================] - 7s 67ms/step - loss: 0.1084 - accuracy: 0.9599 - val_loss: 0.2900 - val_accuracy: 0.9046\n",
      "Epoch 14/20\n",
      "99/99 [==============================] - 7s 67ms/step - loss: 0.1008 - accuracy: 0.9586 - val_loss: 0.2687 - val_accuracy: 0.9097\n",
      "Epoch 15/20\n",
      "99/99 [==============================] - 7s 67ms/step - loss: 0.1161 - accuracy: 0.9609 - val_loss: 0.2537 - val_accuracy: 0.9109\n",
      "Epoch 16/20\n",
      "99/99 [==============================] - 7s 67ms/step - loss: 0.1089 - accuracy: 0.9570 - val_loss: 0.2398 - val_accuracy: 0.9135\n",
      "Epoch 17/20\n",
      "99/99 [==============================] - 7s 67ms/step - loss: 0.0821 - accuracy: 0.9714 - val_loss: 0.2811 - val_accuracy: 0.9160\n",
      "Epoch 18/20\n",
      "99/99 [==============================] - 7s 67ms/step - loss: 0.0851 - accuracy: 0.9704 - val_loss: 0.2861 - val_accuracy: 0.9109\n",
      "Epoch 19/20\n",
      "99/99 [==============================] - 7s 67ms/step - loss: 0.0671 - accuracy: 0.9752 - val_loss: 0.3052 - val_accuracy: 0.9135\n",
      "Epoch 20/20\n",
      "99/99 [==============================] - 7s 67ms/step - loss: 0.0766 - accuracy: 0.9701 - val_loss: 0.3018 - val_accuracy: 0.9097\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\"\n",
    "# sess = tf.Session(config=tf.ConfigProto(device_count={'GPU': 0}))\n",
    "\n",
    "# with tf.device('/CPU:0'):\n",
    "#     history = model.fit(X_train, \n",
    "#                             y_train, \n",
    "#                             batch_size = 32, \n",
    "#                             verbose = 1, \n",
    "#                             epochs = 20,      \n",
    "#                             validation_data=(X_test,y_test),\n",
    "#                             shuffle = True\n",
    "#                         )\n",
    "history = model.fit(X_train, \n",
    "                            y_train, \n",
    "                            batch_size = 32, \n",
    "                            verbose = 1, \n",
    "                            epochs = 20,      \n",
    "                            validation_data=(X_test,y_test),\n",
    "                            shuffle = True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 8s 313ms/step - loss: 0.3018 - accuracy: 0.9097\n",
      "Accuracy =  90.96692204475403 %\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    _, acc = model.evaluate(X_test, y_test)\n",
    "print(\"Accuracy = \", (acc * 100.0), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mythreshold=0.5\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "y_pred = (model.predict(X_test)>= mythreshold).astype(int)\n",
    "cm=confusion_matrix(y_test, y_pred)  \n",
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "y_preds = model.predict(X_test).ravel()\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_preds)\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'y--')\n",
    "plt.plot(fpr, tpr, marker='.')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc\n",
    "auc_value = auc(fpr, tpr)\n",
    "print(\"Area under curve, AUC = \", auc_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "len(tf.config.experimental.list_physical_devices(\"GPU\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.experimental.get_memory_info('GPU:0')['current'] / 10**9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "c = tf.matmul(a, b)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0ae1a202789a8f0c49aad3395cab080c533da2fe719810ab85dd6e21042af8d8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
